{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "996d5f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import argparse\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e1642c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取训练文本\n",
    "def get_texts_from_textsPath(folder_path,df):\n",
    "    texts=[]\n",
    "    for i in df['guid']:\n",
    "        file = \"./data/\"+str(i)+\".txt\"\n",
    "        with open(file, \"r\",encoding=\"GB18030\") as infile:\n",
    "            content = infile.read()\n",
    "            texts.append(content)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取训练图片\n",
    "def get_valid_imagesPath_from_directory(folder_path ,df):\n",
    "    image_paths = []\n",
    "    for ind in df['guid']:\n",
    "        image_path = folder_path+str(ind)+\".jpg\"\n",
    "        image = cv2.imread(image_path)\n",
    "        height,width,channels = image.shape\n",
    "        image_paths.append(image_path)\n",
    "    \n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f311d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据预处理\n",
    "\n",
    "train_label_path = \"train.txt\"\n",
    "train_label_df = pd.read_csv(train_label_path,sep=\",\")\n",
    "\n",
    "#将情感标签替换为数字\n",
    "column_dict = {\"positive\": 0, \"negative\": 1,\"neutral\":2}\n",
    "new_df = train_label_df.replace({\"tag\": column_dict})\n",
    "labels = list(new_df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fc7df123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @AmitSwami77: The conspirators have an evil eye & are now set to physically attack Asaram Bapu Ji! #WeDemandSafety4Bapuji http://t.co/N8…\\n', 'Waxwing trills, Chickadees calling \"here sweetie\", enthusiastic athletes, blue sky & snow at #ualbertafarm #UAlberta \\n', '@NYSE is looking a little despondent today...??? http://t.co/o5xiKyJgT7\\n', 'FERVENT | S,M,L | 140k free PLASTIC CLIP, keychain rubber AND sticker 085725737197 / 28ae36f3 \\n', 'Nice day chilling in the park yesterday relieved my mood for a short while. #friends #summer #outside #depression \\n', 'Ford : F-350 Lariat 6.4L 2008 Lariat Heated Leather Rear Camera 2008 ford f 250 diesel 4 x… \\n', 'RT @MOVIEMEMORlES: Furious 7 http://t.co/CEPxKf3QlY\\n', '@MattSmith1230 @ProFlowers The flowers look like a dejected King Tritan: \\n', '#廃墟 #廃線 #abandoned #写真撮ってる人と繋がりたい #写真好きな人と繋がりたい \\n', \"RT @Pablothemako: UPDATE!Navy discarded ilegal fishing after boarding chinese vessels in #Chile's Excl Econ Zone htt… \\n\"]\n",
      "['./data/4597.jpg', './data/26.jpg', './data/4383.jpg', './data/212.jpg', './data/2626.jpg', './data/3042.jpg', './data/4713.jpg', './data/2073.jpg', './data/2020.jpg', './data/2688.jpg']\n"
     ]
    }
   ],
   "source": [
    "# 原始数据\n",
    "image_paths = get_valid_imagesPath_from_directory(\"./data/\",new_df)\n",
    "texts = get_texts_from_textsPath(\"./data/\",new_df)\n",
    "print(texts[:10])\n",
    "print(image_paths[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22c7def4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集\n",
    "image_paths_train, image_paths_val, texts_train, texts_val, labels_train, labels_val = train_test_split(\n",
    "    image_paths, texts, labels, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0cb9faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#文本预处理\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')#分词器\n",
    "pretrained_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "max_length = 147\n",
    "\n",
    "def text_preprocess(texts):\n",
    "    tokenized_texts = [tokenizer(text,padding='max_length',max_length=max_length,truncation=True,return_tensors=\"pt\") for text in texts]\n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c20b685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts_train = text_preprocess(texts_train)\n",
    "tokenized_texts_val = text_preprocess(texts_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc554b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81f37732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练集类\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, image_paths, tokenized_texts, labels,transform=None):\n",
    "        self.image_paths = image_paths     \n",
    "        self.transform = transform\n",
    "        self.input_ids = [x['input_ids'] for x in tokenized_texts]\n",
    "        self.attention_mask = [x['attention_mask'] for x in tokenized_texts]\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_ids = torch.tensor(self.input_ids[index])\n",
    "        attention_mask = torch.tensor(self.attention_mask[index])\n",
    "        labels = torch.tensor(self.labels[index])\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        return image ,input_ids, attention_mask, labels\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d874781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset(image_paths_train, tokenized_texts_train, labels_train, transform)\n",
    "dataset_val = Dataset(image_paths_val,tokenized_texts_val, labels_val, transform)\n",
    "\n",
    "#run test\n",
    "x_train = Dataset(image_paths_train[:1000], tokenized_texts_train[:1000], labels_train[:1000], transform)\n",
    "x_val = Dataset(image_paths_val[:200],tokenized_texts_val[:200], labels_val[:200], transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adbb9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片特征提取模型\n",
    "class ImageFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageFeatureExtractor, self).__init__()\n",
    "        self.resnet = resnet50(pretrained=True) \n",
    "    \n",
    "    def forward(self, image):\n",
    "        features = self.resnet(image)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0123ae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本特征提取模型\n",
    "class TextFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TextFeatureExtractor, self).__init__()\n",
    "        self.bert = pretrained_model\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  \n",
    "        output = pooled_output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00edae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多模态融合模型定义\n",
    "class MixModel(nn.Module):\n",
    "    def __init__(self, num_classes,option):\n",
    "        super(MixModel, self).__init__()\n",
    "        self.image_extractor = ImageFeatureExtractor()  \n",
    "        self.text_encoder = TextFeatureExtractor()\n",
    "        self.option=option\n",
    "        \n",
    "        #仅图像\n",
    "        self.classifier0 = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1000, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4),\n",
    "             nn.Linear(256, num_classes),\n",
    "            nn.ReLU(inplace=True),\n",
    "           \n",
    "        )\n",
    "        #仅文本\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        #多模态融合\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1768, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(1024, num_classes),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, image, input_ids,attention_mask):\n",
    "        if(self.option==0):#图\n",
    "            image_features = self.image_extractor(image)\n",
    "            output = image_features\n",
    "            output = self.classifier0(image_features)\n",
    "        elif(self.option==1):#文本\n",
    "            text_features = self.text_encoder(input_ids, attention_mask)\n",
    "            output = self.classifier1(text_features)\n",
    "        else:#图文\n",
    "            image_features = self.image_extractor(image)\n",
    "            text_features = self.text_encoder(input_ids,attention_mask)\n",
    "            fusion_features = torch.cat((text_features,image_features), dim=-1)\n",
    "            output = self.classifier2(fusion_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6029ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer,device):\n",
    "    model.train()  \n",
    "    running_loss = 0\n",
    "    total_correct = 0 \n",
    "    for images, input_ids, attention_mask, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.squeeze(1).to(device)\n",
    "        attention_mask = attention_mask.to(device)    \n",
    "        labels = labels.to(device)  \n",
    "        optimizer.zero_grad()     \n",
    "        outputs = model(images, input_ids,attention_mask)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total_correct += torch.sum(preds == labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = total_correct.item() / len(train_loader.dataset)\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78704739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "def predict_model(model, test_loader,device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for images,input_ids, attention_mask,  _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.squeeze(1).to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(images, input_ids,attention_mask)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ab6ab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5c8619cbf775>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(self.input_ids[index])\n",
      "<ipython-input-11-5c8619cbf775>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(self.attention_mask[index])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1b49832921c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mval_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# 计算验证集准确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-3e68a57ceb17>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtotal_correct\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = [0.001,0.01,0.1]\n",
    "batch_size = 10\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "\n",
    "loader_train = DataLoader(x_train, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(x_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#既有图片又有文本\n",
    "for l in lr:\n",
    "    model = MixModel(3,2)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), l)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_model(model, loader_train, criterion, optimizer,device)\n",
    "        val_predictions = predict_model(model, loader_val,device)\n",
    "        #数组格式\n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_labels = np.array(labels_val)\n",
    "        sum = 0\n",
    "        for x in range(len(val_predictions)):\n",
    "            if (val_predictions[x] == val_labels[x]):\n",
    "                       sum += 1\n",
    "        val_acc = sum / len(val_labels)\n",
    "        if(val_acc>best_acc):\n",
    "            best_acc = val_acc\n",
    "            best_model = model\n",
    "        print(f\"lr: {l}, Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "print(\"最佳准确率\")\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7165239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#只有图片\n",
    "for l in lr:\n",
    "    model = MixModel(3,0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_model(model, loader_train, criterion, optimizer,device)\n",
    "        val_predictions = predict_model(model, loader_val,device)\n",
    "        # 计算验证集准确率    \n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_labels = np.array(labels_val)\n",
    "        val_acc = (val_predictions == val_labels).sum() / len(val_labels)\n",
    "        if(val_acc>best_acc):\n",
    "            best_acc = val_acc\n",
    "        print(f\"lr: {l}, Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "print(\"最佳准确率\")\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ad13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#只有文本\n",
    "for l in lr:\n",
    "    model = MixModel(3,1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=l)\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_model(model, loader_train, criterion, optimizer,device)\n",
    "        val_predictions = predict_model(model, loader_val,device)\n",
    "        # 计算验证集准确率    \n",
    "        val_predictions = np.array(val_predictions)\n",
    "        val_labels = np.array(labels_val)\n",
    "        val_acc = (val_predictions == val_labels).sum() / len(val_labels)\n",
    "        if(val_acc>best_acc):\n",
    "            best_acc = val_acc\n",
    "        print(f\"lr: {l}, Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "print(\"最佳准确率\")\n",
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5afdb818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载测试集并预处理\n",
    "test_path = \"test_without_label.txt\"\n",
    "test_df = pd.read_csv(test_path,sep=\",\")\n",
    "test_df.iloc[:,-1]=0\n",
    "test_labels = np.array(test_df['tag'])\n",
    "\n",
    "#image_paths\n",
    "image_paths_test = get_valid_imagesPath_from_directory(\"./data/\",test_df)\n",
    "test_texts = get_texts_from_textsPath(\"./data/\",test_df)\n",
    "\n",
    "tokenized_texts_test = text_preprocess(test_texts)\n",
    "dataset_test = Dataset(image_paths_test, tokenized_texts_test, test_labels, transform)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5327cc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-6a9fc1dbcbbb>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(self.input_ids[index])\n",
      "<ipython-input-48-6a9fc1dbcbbb>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(self.attention_mask[index])\n"
     ]
    }
   ],
   "source": [
    "#最优模型预测\n",
    "test_predictions = predict_model(best_model, loader_test, device)  \n",
    "test_predictions = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fd5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据文件\n",
    "test_data_file = pd.read_csv(\"test_without_label.txt\")['guid'].values\n",
    "\n",
    "# 将标签和预测结果写入test_without_label文件\n",
    "with open('test_without_label.txt', 'w') as f:\n",
    "    f.write('guid,tag\\n')\n",
    "    for i in range(len(test_data_file)):\n",
    "        if predict_final[i] == 0:\n",
    "            f.write(str(test_data_file[i]) + ',' + \"positive\" + '\\n')\n",
    "        elif predict_final[i] == 1:\n",
    "            f.write(str(test_data_file[i]) + ',' + \"negative\" + '\\n')\n",
    "        else:\n",
    "            f.write(str(test_data_file[i]) + ',' + \"neutral\" + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e30c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553d0440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
